{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "31d9a4c9",
      "metadata": {
        "origin_pos": 0,
        "id": "31d9a4c9"
      },
      "source": [
        "# Using Jupyter Notebooks\n",
        ":label:`sec_jupyter`\n",
        "\n",
        "\n",
        "This section describes how to edit and run the code\n",
        "in each section of this book\n",
        "using the Jupyter Notebook. Make sure you have\n",
        "installed Jupyter and downloaded the\n",
        "code as described in\n",
        ":ref:`chap_installation`.\n",
        "If you want to know more about Jupyter see the excellent tutorial in\n",
        "their [documentation](https://jupyter.readthedocs.io/en/latest/).\n",
        "\n",
        "\n",
        "## Editing and Running the Code Locally\n",
        "\n",
        "Suppose that the local path of the book's code is `xx/yy/d2l-en/`. Use the shell to change the directory to this path (`cd xx/yy/d2l-en`) and run the command `jupyter notebook`. If your browser does not do this automatically, open http://localhost:8888 and you will see the interface of Jupyter and all the folders containing the code of the book, as shown in :numref:`fig_jupyter00`.\n",
        "\n",
        "![The folders containing the code of this book.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter00.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter00`\n",
        "\n",
        "\n",
        "You can access the notebook files by clicking on the folder displayed on the webpage.\n",
        "They usually have the suffix \".ipynb\".\n",
        "For the sake of brevity, we create a temporary \"test.ipynb\" file.\n",
        "The content displayed after you click it is\n",
        "shown in :numref:`fig_jupyter01`.\n",
        "This notebook includes a markdown cell and a code cell. The content in the markdown cell includes \"This Is a Title\" and \"This is text.\".\n",
        "The code cell contains two lines of Python code.\n",
        "\n",
        "![Markdown and code cells in the \"text.ipynb\" file.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter01.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter01`\n",
        "\n",
        "\n",
        "Double click on the markdown cell to enter edit mode.\n",
        "Add a new text string \"Hello world.\" at the end of the cell, as shown in :numref:`fig_jupyter02`.\n",
        "\n",
        "![Edit the markdown cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter02.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter02`\n",
        "\n",
        "\n",
        "As demonstrated in :numref:`fig_jupyter03`,\n",
        "click \"Cell\" $\\rightarrow$ \"Run Cells\" in the menu bar to run the edited cell.\n",
        "\n",
        "![Run the cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter03.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter03`\n",
        "\n",
        "After running, the markdown cell is shown in :numref:`fig_jupyter04`.\n",
        "\n",
        "![The markdown cell after running.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter04.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter04`\n",
        "\n",
        "\n",
        "Next, click on the code cell. Multiply the elements by 2 after the last line of code, as shown in :numref:`fig_jupyter05`.\n",
        "\n",
        "![Edit the code cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter05.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter05`\n",
        "\n",
        "\n",
        "You can also run the cell with a shortcut (\"Ctrl + Enter\" by default) and obtain the output result from :numref:`fig_jupyter06`.\n",
        "\n",
        "![Run the code cell to obtain the output.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter06.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter06`\n",
        "\n",
        "\n",
        "When a notebook contains more cells, we can click \"Kernel\" $\\rightarrow$ \"Restart & Run All\" in the menu bar to run all the cells in the entire notebook. By clicking \"Help\" $\\rightarrow$ \"Edit Keyboard Shortcuts\" in the menu bar, you can edit the shortcuts according to your preferences.\n",
        "\n",
        "## Advanced Options\n",
        "\n",
        "Beyond local editing two things are quite important: editing the notebooks in the markdown format and running Jupyter remotely.\n",
        "The latter matters when we want to run the code on a faster server.\n",
        "The former matters since Jupyter's native ipynb format stores a lot of auxiliary data that is\n",
        "irrelevant to the content,\n",
        "mostly related to how and where the code is run.\n",
        "This is confusing for Git, making\n",
        "reviewing contributions very difficult.\n",
        "Fortunately there is an alternative---native editing in the markdown format.\n",
        "\n",
        "### Markdown Files in Jupyter\n",
        "\n",
        "If you wish to contribute to the content of this book, you need to modify the\n",
        "source file (md file, not ipynb file) on GitHub.\n",
        "Using the notedown plugin we\n",
        "can modify notebooks in the md format directly in Jupyter.\n",
        "\n",
        "\n",
        "First, install the notedown plugin, run the Jupyter Notebook, and load the plugin:\n",
        "\n",
        "```\n",
        "pip install d2l-notedown  # You may need to uninstall the original notedown.\n",
        "jupyter notebook --NotebookApp.contents_manager_class='notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "You may also turn on the notedown plugin by default whenever you run the Jupyter Notebook.\n",
        "First, generate a Jupyter Notebook configuration file (if it has already been generated, you can skip this step).\n",
        "\n",
        "```\n",
        "jupyter notebook --generate-config\n",
        "```\n",
        "\n",
        "Then, add the following line to the end of the Jupyter Notebook configuration file (for Linux or macOS, usually in the path `~/.jupyter/jupyter_notebook_config.py`):\n",
        "\n",
        "```\n",
        "c.NotebookApp.contents_manager_class = 'notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "After that, you only need to run the `jupyter notebook` command to turn on the notedown plugin by default.\n",
        "\n",
        "### Running Jupyter Notebooks on a Remote Server\n",
        "\n",
        "Sometimes, you may want to run Jupyter notebooks on a remote server and access it through a browser on your local computer. If Linux or macOS is installed on your local machine (Windows can also support this function through third-party software such as PuTTY), you can use port forwarding:\n",
        "\n",
        "```\n",
        "ssh myserver -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "The above string `myserver` is the address of the remote server.\n",
        "Then we can use http://localhost:8888 to access the remote server `myserver` that runs Jupyter notebooks. We will detail on how to run Jupyter notebooks on AWS instances\n",
        "later in this appendix.\n",
        "\n",
        "### Timing\n",
        "\n",
        "We can use the `ExecuteTime` plugin to time the execution of each code cell in Jupyter notebooks.\n",
        "Use the following commands to install the plugin:\n",
        "\n",
        "```\n",
        "pip install jupyter_contrib_nbextensions\n",
        "jupyter contrib nbextension install --user\n",
        "jupyter nbextension enable execute_time/ExecuteTime\n",
        "```\n",
        "\n",
        "## Summary\n",
        "\n",
        "* Using the Jupyter Notebook tool, we can edit, run, and contribute to each section of the book.\n",
        "* We can run Jupyter notebooks on remote servers using port forwarding.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Edit and run the code in this book with the Jupyter Notebook on your local machine.\n",
        "1. Edit and run the code in this book with the Jupyter Notebook *remotely* via port forwarding.\n",
        "1. Compare the running time of the operations $\\mathbf{A}^\\top \\mathbf{B}$ and $\\mathbf{A} \\mathbf{B}$ for two square matrices in $\\mathbb{R}^{1024 \\times 1024}$. Which one is faster?\n",
        "\n",
        "\n",
        "[Discussions](https://discuss.d2l.ai/t/421)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install together\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP4aKsg-M5FL",
        "outputId": "f7d9210b-f885-43bf-c02e-39ed2357df19"
      },
      "id": "SP4aKsg-M5FL",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.11)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (1.26.4)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from together) (17.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.4.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: eval-type-backport, together\n",
            "Successfully installed eval-type-backport-0.2.2 together-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWCaawsZlony",
        "outputId": "684b0951-fc16-4af0-bbd4-564e7bfac45d"
      },
      "id": "OWCaawsZlony",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.31)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=cc12f32934df176c50d08addd18d9a2b2ccb58ece63f6ca01769a76eac42eb78\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langsmith 0.3.5 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "openai 1.61.1 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " TOGETHER_API_KEY = \"c2a928e074a7572ceb62b16364efffb8e58571520f25568594d373339bb9847c\""
      ],
      "metadata": {
        "id": "toiz9UyAPa6d"
      },
      "id": "toiz9UyAPa6d",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from together import Together\n",
        "\n",
        "client = Together(api_key = TOGETHER_API_KEY)\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "  model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"What are the top 3 things to do in New York?\"}],\n",
        "  stream=True,\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "  print(chunk.choices[0].delta.content or \"\", end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCkF6bRdNMhE",
        "outputId": "7727f4f7-2598-48fa-8d3c-4c0a5e0f0164"
      },
      "id": "RCkF6bRdNMhE",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The city that never sleeps - New York! There are countless things to see and do in the Big Apple, but here are the top 3 things to do in New York:\n",
            "\n",
            "1. **Visit the Statue of Liberty and Ellis Island**: Take a ferry to Liberty Island to see the iconic Statue of Liberty up close. You can also visit the Ellis Island Immigration Museum to learn about the history of immigration in the United States. This is a must-do experience that offers breathtaking views of the Manhattan skyline.\n",
            "\n",
            "2. **Explore the Metropolitan Museum of Art**: The Met, as it's affectionately known, is one of the world's largest and most famous museums. With a collection that spans over 5,000 years of human history, you'll find something to interest everyone. From ancient Egyptian artifacts to modern art, the Met is a treasure trove of culture and history.\n",
            "\n",
            "3. **Walk across the Brooklyn Bridge**: This iconic bridge offers stunning views of the Manhattan skyline, the East River, and Brooklyn. Take a leisurely walk across the bridge and stop at the Brooklyn Bridge Park for some great food and drink options. You can also visit the Brooklyn Bridge's pedestrian walkway, which offers spectacular views of the city.\n",
            "\n",
            "Of course, there are many more things to see and do in New York, but these three experiences are a great starting point for your trip.\n",
            "\n",
            "Honorable mentions:\n",
            "\n",
            "- Visit the Top of the Rock Observation Deck for panoramic views of the city\n",
            "- Take a stroll through Central Park, a tranquil oasis in the middle of Manhattan\n",
            "- Catch a Broadway show, one of the world's most famous theater scenes\n",
            "- Explore the vibrant neighborhoods of Chinatown, Little Italy, and Greenwich Village\n",
            "- Visit the 9/11 Memorial & Museum, a poignant tribute to the victims of the 2001 attacks\n",
            "\n",
            "Remember to plan ahead, as some of these attractions can be quite crowded and popular. Enjoy your trip to New York!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "-qXerpzRNPG6"
      },
      "id": "-qXerpzRNPG6"
    },
    {
      "cell_type": "code",
      "source": [
        "from requests import Request, Session\n",
        "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
        "import json\n",
        "\n",
        "url = 'https://sandbox-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "parameters = {\n",
        "  'start':'1',\n",
        "  'limit':'5000',\n",
        "  'convert':'USD'\n",
        "}\n",
        "headers = {\n",
        "  'Accepts': 'application/json',\n",
        "  'X-CMC_PRO_API_KEY': 'a1f30c04-11ee-404e-8fca-40a7b9250fa7',\n",
        "}\n",
        "\n",
        "session = Session()\n",
        "session.headers.update(headers)\n",
        "\n",
        "try:\n",
        "  response = session.get(url, params=parameters)\n",
        "  data = json.loads(response.text)\n",
        "  print(type(data))\n",
        "  print(data['data'][0]['quote']['USD']['price'])\n",
        "  # print(data['quote'][\"usd\"])\n",
        "except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
        "  print(e)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYpf1rklRFPV",
        "outputId": "995f7958-24fd-4bd1-e22c-7097685db9e3"
      },
      "id": "HYpf1rklRFPV",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "0.615813938026909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_crypto_price(symbol):\n",
        "    url = 'https://sandbox-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "    parameters = {\n",
        "      'start':'1',\n",
        "      'limit':'5000',\n",
        "      'convert':'USD'\n",
        "    }\n",
        "    headers = {\n",
        "      'Accepts': 'application/json',\n",
        "      'X-CMC_PRO_API_KEY': 'a1f30c04-11ee-404e-8fca-40a7b9250fa7',\n",
        "    }\n",
        "\n",
        "    session = Session()\n",
        "    session.headers.update(headers)\n",
        "    try:\n",
        "        response = session.get(url, params=parameters)\n",
        "        data = json.loads(response.text)\n",
        "        # print(data)\n",
        "        return data['data'][0]['quote']['USD']['price']\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error fetching price: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "T_RFDeLoRLLV"
      },
      "id": "T_RFDeLoRLLV",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from googletrans import Translator, LANGUAGES\n",
        "\n",
        "# translator = Translator()\n",
        "\n",
        "# def translate_to_english(text):\n",
        "#     try:\n",
        "#         detected_lang = translator.detect(text).lang\n",
        "#         if detected_lang == \"en\":\n",
        "#             return text  # No translation needed\n",
        "\n",
        "#         translated_text = translator.translate(text, src=detected_lang, dest=\"en\").text\n",
        "#         return f\"(Translated from {LANGUAGES[detected_lang]}): {translated_text}\"\n",
        "\n",
        "#     except Exception as e:\n",
        "#         return f\"Translation error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "b2ukIErW89v7"
      },
      "id": "b2ukIErW89v7",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate_to_english(\"How are you?\")"
      ],
      "metadata": {
        "id": "IziPrhT4_LiV",
        "outputId": "502adad1-237d-44c7-9f3e-5cdee0e51999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "IziPrhT4_LiV",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How are you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "# import openai\n",
        "\n",
        "# client = openai.OpenAI(\n",
        "#     base_url = \"https://api.together.xyz/v1\",\n",
        "#     api_key = os.environ['TOGETHER_API_KEY'],\n",
        "# )\n",
        "\n",
        "# tools = [\n",
        "#   {\n",
        "#     \"type\": \"function\",\n",
        "#     \"function\": {\n",
        "#       \"name\": \"get_crypto_price\",\n",
        "#       \"description\": \"Get the current price of the bitcoin\",\n",
        "#       \"parameters\": {\n",
        "#         \"type\": \"object\",\n",
        "#         \"properties\": {\n",
        "#           \"symbol\": {\n",
        "#             \"type\": \"string\",\n",
        "#             \"description\": \"The symbol of the cryptocurrency\"\n",
        "#           },\n",
        "#           \"required\" : [\"symbol\"],\n",
        "#           \"unit\": {\n",
        "#             \"type\": \"string\",\n",
        "#             \"enum\":[]\n",
        "\n",
        "#           }\n",
        "#         }\n",
        "#       }\n",
        "#     }\n",
        "#   }\n",
        "# ]\n",
        "\n",
        "# messages = [\n",
        "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\"},\n",
        "#     {\"role\": \"user\", \"content\": \"What is the current temperature of New York, San Francisco and Chicago?\"}\n",
        "# ]\n",
        "\n",
        "# response = client.chat.completions.create(\n",
        "#     model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "#     messages=messages,\n",
        "#     tools=tools,\n",
        "#     tool_choice=\"auto\",\n",
        "# )\n",
        "\n",
        "# print(json.dumps(response.choices[0].message.model_dump()['tool_calls'], indent=2))"
      ],
      "metadata": {
        "id": "JweDNUHa0jV_"
      },
      "id": "JweDNUHa0jV_",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text):\n",
        "  sys_msg = \"\"\"You are a helpful assistant that can translate text from one language to another. Below are a few examples demonstrating how you\n",
        "  should translate sentences from one language to another. When a user asks for a translation, you should provide the equivalent sentence in the\n",
        "  target language. Just provide the translated sentence, nothing else.\n",
        "  Examples :\n",
        "  1. Translate from Spanish to English:\n",
        "  User Input: \"¿Cómo estás?\"\n",
        "  Agent Response: \"How are you?\"\n",
        "\n",
        "  2. Translate from French to English:\n",
        "  User Input: \"Où est la bibliothèque?\"\n",
        "  Agent Response: \"Where is the library?\"\n",
        "\n",
        "  3. Translate from German to English:\n",
        "  User Input: \"Ich habe Hunger.\"\n",
        "  Agent Response: \"I am hungry.\"\n",
        "\n",
        "  \"\"\"\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": sys_msg},\n",
        "    {\"role\": \"user\", \"content\": text}\n",
        "  ]\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    messages=messages,\n",
        "  )\n",
        "  return response.choices[0].message.content\n",
        "\n"
      ],
      "metadata": {
        "id": "LTuiiOkiILzH"
      },
      "id": "LTuiiOkiILzH",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = {\n",
        "    \"BitcoinPrice\" : {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": get_crypto_price,\n",
        "        \"description\": \"Get the current price of the bitcoin\"\n",
        "    },\n",
        "    \"Translate\" : {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": translate,\n",
        "        \"description\": \"Translate text from one language to another.\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "IsNzVp3mLTWV"
      },
      "id": "IsNzVp3mLTWV",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "id": "YALL_cjnMNu0",
        "outputId": "0f080dc1-bab1-4294-feaa-4f38d310c7ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YALL_cjnMNu0",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BitcoinPrice': {'type': 'function',\n",
              "  'function': <function __main__.get_crypto_price(symbol)>,\n",
              "  'description': 'Get the current price of the bitcoin'},\n",
              " 'Translate': {'type': 'function',\n",
              "  'function': <function __main__.translate(text)>,\n",
              "  'description': 'Translate text from one language to another.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "import json\n",
        "tools = {\n",
        "    \"BitcoinPrice\": {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {  # Specify function name instead of the actual function object\n",
        "            \"name\": \"get_crypto_price\",\n",
        "            \"description\": \"Get the current price of Bitcoin or Ethereum\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"symbol\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The symbol of the cryptocurrency (BTC or ETH)\",\n",
        "                        \"enum\": [\"BTC\", \"ETH\"],  # Add enum for allowed values\n",
        "                    }\n",
        "                },\n",
        "                \"required\": []  # No required parameters (symbol has a default)\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Translate\": {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {  # Specify function name instead of the actual function object\n",
        "            \"name\": \"translate\",\n",
        "            \"description\": \"Translate text from one language to another.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"text\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The text to be translated\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"text\"]  # Text is required for translation\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# prompt =\n",
        "response = together.Completion.create(\n",
        "model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "prompt= \"Hi\",  # Use the original or translated user input as the prompt\n",
        "tools=tools,\n",
        "tool_choice=\"auto\",\n",
        "max_tokens=1000\n",
        ")\n",
        "print(response.choices[0].text)\n",
        "\n",
        "    # ... (Rest of your response handling) ..."
      ],
      "metadata": {
        "id": "6Iq0A9A9QSn9",
        "outputId": "6670fe4b-612f-4ae0-b7a8-cf8521afaf5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6Iq0A9A9QSn9",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-060b6eb7f26c>:42: DeprecationWarning: Call to deprecated function create.\n",
            "  response = together.Completion.create(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " href=\"https://www.bbc.co.uk/news/uk-politics-56711121\">BBC News</a> article about the UK's new Prime Minister, Rishi Sunak, and his plans for the country.</p>\n",
            "</body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "This code is a simple HTML document that includes a link to a BBC News article about the UK's new Prime Minister, Rishi Sunak. The link is in the format of an HTML anchor tag (`<a>`) with the text \"BBC News\" and the URL of the article. The article is not included in the code, but it is linked to from the HTML document.\n",
            "\n",
            "To use this code, you would save it to a file with a `.html` extension (e.g. `sunak.html`) and open it in a web browser to view the link to the BBC News article. \n",
            "\n",
            "### Step 2: Add a link to the article\n",
            "\n",
            "To add a link to the article, you would need to replace the URL in the anchor tag with the actual URL of the article. You can find the URL of the article by copying and pasting it from the address bar of your web browser when you visit the article.\n",
            "\n",
            "For example, if the URL of the article is `https://www.bbc.co.uk/news/uk-politics-56711121`, you would replace the URL in the anchor tag with this URL.\n",
            "\n",
            "Here is the updated code:\n",
            "\n",
            "```html\n",
            "<html>\n",
            "  <body>\n",
            "    <p>Here is a link to a BBC News article about the UK's new Prime Minister, Rishi Sunak:</p>\n",
            "    <p><a href=\"https://www.bbc.co.uk/news/uk-politics-56711121\">BBC News</a></p>\n",
            "  </body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "This code is the same as the previous code, but with the URL of the article updated to the actual URL of the article.\n",
            "\n",
            "### Step 3: Add a title to the article\n",
            "\n",
            "To add a title to the article, you would need to add a title element to the HTML document. The title element should be placed inside the head element of the HTML document.\n",
            "\n",
            "Here is the updated code:\n",
            "\n",
            "```html\n",
            "<html>\n",
            "  <head>\n",
            "    <title>UK's new Prime Minister, Rishi Sunak</title>\n",
            "  </head>\n",
            "  <body>\n",
            "    <p>Here is a link to a BBC News article about the UK's new Prime Minister, Rishi Sunak:</p>\n",
            "    <p><a href=\"https://www.bbc.co.uk/news/uk-politics-56711121\">BBC News</a></p>\n",
            "  </body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "This code adds a title element to the HTML document with the text \"UK's new Prime Minister, Rishi Sunak\". This title will appear in the title bar of the web browser when the HTML document is opened.\n",
            "\n",
            "### Step 4: Add a description to the article\n",
            "\n",
            "To add a description to the article, you would need to add a meta element to the HTML document. The meta element should be placed inside the head element of the HTML document.\n",
            "\n",
            "Here is the updated code:\n",
            "\n",
            "```html\n",
            "<html>\n",
            "  <head>\n",
            "    <title>UK's new Prime Minister, Rishi Sunak</title>\n",
            "    <meta name=\"description\" content=\"Read the latest news about the UK's new Prime Minister, Rishi Sunak, and his plans for the country.\">\n",
            "  </head>\n",
            "  <body>\n",
            "    <p>Here is a link to a BBC News article about the UK's new Prime Minister, Rishi Sunak:</p>\n",
            "    <p><a href=\"https://www.bbc.co.uk/news/uk-politics-56711121\">BBC News</a></p>\n",
            "  </body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "This code adds a meta element to the HTML document with the name \"description\" and the content \"Read the latest news about the UK's new Prime Minister, Rishi Sunak, and his plans for the country.\". This description will appear in the search engine results when the HTML document is searched for.\n",
            "\n",
            "### Step 5: Add keywords to the article\n",
            "\n",
            "To add keywords to the article, you would need to add a meta element to the HTML document. The meta element should be placed inside the head element of the HTML document.\n",
            "\n",
            "Here is the updated code:\n",
            "\n",
            "```html\n",
            "<html>\n",
            "  <head>\n",
            "    <title>UK's new Prime Minister, Rishi Sunak</title>\n",
            "    <meta name=\"description\" content=\"Read the latest news about the UK's new Prime Minister, Rishi Sunak, and his plans for the country.\">\n",
            "    <meta name=\"keywords\" content=\"Rishi Sunak, UK Prime Minister, politics, news\">\n",
            "  </head>\n",
            "  <body>\n",
            "    <p>Here is a link to a BBC News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = together.Completion.create(\n",
        "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "        # prompt=\"\\n\".join([msg[\"content\"] for msg in conversation_history]),\n",
        "        tools = tools,\n",
        "        tool_choice = \"auto\",\n",
        "        max_tokens=1000,\n",
        "        prompt = \"price of the bitcoin\"\n",
        "    )\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "id": "OgC7GFknMWPU",
        "outputId": "aabee353-02ad-40ff-93d6-a3e48f6c5bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "id": "OgC7GFknMWPU",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-398652525531>:1: DeprecationWarning: Call to deprecated function create.\n",
            "  response = together.Completion.create(\n",
            "/usr/local/lib/python3.11/dist-packages/together/legacy/complete.py:68: UserWarning: The use of together.api_key is deprecated and will be removed in the next major release. Please set the TOGETHER_API_KEY environment variable instead.\n",
            "  warnings.warn(API_KEY_WARNING)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Object of type function is not JSON serializable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-398652525531>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = together.Completion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# prompt=\"\\n\".join([msg[\"content\"] for msg in conversation_history]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtool_choice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/legacy/base.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         )\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/legacy/complete.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, prompt, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTogether\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prompt, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, presence_penalty, frequency_penalty, min_p, logit_bias, seed, stream, logprobs, echo, n, safety_model, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         ).model_dump(exclude_none=True)\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         response, _, _ = requestor.request(\n\u001b[0m\u001b[1;32m    124\u001b[0m             options=TogetherRequest(\n\u001b[1;32m    125\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/abstract/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, options, stream, remaining_retries, request_timeout)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     ]:\n\u001b[0;32m--> 242\u001b[0;31m         result = self.request_raw(\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mremaining_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremaining_retries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/abstract/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, options, remaining_retries, stream, request_timeout, absolute)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mabsolute\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     ) -> requests.Response:\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_request_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_thread_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"session\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/abstract/api_requestor.py\u001b[0m in \u001b[0;36m_prepare_request_raw\u001b[0;34m(self, options, absolute)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mdata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    181\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Object of type function is not JSON serializable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"translate 'வணக்கம், நீங்கள் எங்கு உள்ளீர்கள்.' in English\")"
      ],
      "metadata": {
        "id": "eN98zKUiJC6H",
        "outputId": "fc2fe75c-2c64-4204-995d-a25549cb4b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "eN98zKUiJC6H",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Hello, where are you from?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"\n",
        "System: You are an AI assistant capable of handling multiple tasks, including cryptocurrency price fetching and language translation.\n",
        "You always respond in a clear, structured, and conversational manner.\n",
        "\n",
        "Context:\n",
        "- The user may ask in different languages; their queries will be translated into English before processing.\n",
        "- If the user asks about cryptocurrency prices, provide the price before responding conversationally.\n",
        "\n",
        "Conversation History:\n",
        "{history}\n",
        "\n",
        "User Input:\n",
        "{user_input}\n",
        "\n",
        "Additional Info:\n",
        "{additional_info}\n",
        "\n",
        "Response:"
      ],
      "metadata": {
        "id": "V_dZ8MCaxu9e"
      },
      "id": "V_dZ8MCaxu9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import together\n",
        "\n",
        "# together.api_key = TOGETHER_API_KEY\n",
        "# # client = Together(api_key = TOGETHER_API_KEY)\n",
        "# conversation_history = []\n",
        "\n",
        "# # def chat_with_llama(prompt):\n",
        "# #     response = together.Completion.create(\n",
        "# #         model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "# #         prompt=prompt,\n",
        "# #         max_tokens=100\n",
        "# #     )\n",
        "# #     # return response[\"choices\"][0][\"text\"]\n",
        "# #     return response.choices[0].text\n",
        "\n",
        "# # print(chat_with_llama(\"What is the current price of Bitcoin?\"))/\n",
        "# def chat_with_agent(user_input):\n",
        "#     global conversation_history\n",
        "#     # if 'translate' in user_input.lower():\n",
        "#     #     return translate_to_english(user_input)\n",
        "#     # Check if the user is asking for crypto prices\n",
        "#     if \"bitcoin\" in user_input.lower() or \"price of\" in user_input.lower():\n",
        "#         symbol = \"BTC\"  # Default to Bitcoin\n",
        "#         if \"ethereum\" in user_input.lower():\n",
        "#             symbol = \"ETH\"\n",
        "#         return get_crypto_price(symbol)\n",
        "\n",
        "#     # messages = [\n",
        "#     # {\"role\": \"system\", \"content\": \"You are a helpful assistant that can access external functions. Your responsibility is to get the bitcoin price from the get_crypto_price tool and translate the text in whatever the language user ask for using the translate_to_english tool keeping the system message in English.\"},\n",
        "#     # {\"role\": \"user\", \"content\": user_input}\n",
        "#     # ]\n",
        "#     # messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "#     conversation_history.append({\"role\": \"system\", \"content\": \"You are a helpful assistant that can access external functions. Your responsibility is to get the bitcoin price from the get_crypto_price tool and translate the text in whatever the language user ask for using the translate_to_english tool keeping the system message in English.\"},)\n",
        "#     conversation_history.append({\"role\": \"user\", \"content\": ques})\n",
        "#     response = together.Completion.create(\n",
        "#         model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "#         # messages=messages,\n",
        "#         prompt=\"\\n\".join([msg[\"content\"] for msg in conversation_history]),\n",
        "#         max_tokens=1000\n",
        "#     )\n",
        "#     # Save AI response in history\n",
        "#     ai_response = response.choices[0].text\n",
        "#     messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "\n",
        "#     conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "#     return ai_response\n",
        "\n",
        "# ques = \"who is the ceo of open ai?\"\n",
        "# print(chat_with_agent(ques))\n",
        "# # Example Usage\n",
        "# # while True:\n",
        "# #     user_input = input(\"You: \")\n",
        "#     # if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "#     #     break\n",
        "#     # print(\"Agent:\", chat_with_agent(user_input))"
      ],
      "metadata": {
        "id": "y6fPOuq5RmJ8"
      },
      "id": "y6fPOuq5RmJ8",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "together.api_key = TOGETHER_API_KEY\n",
        "conversation_history = []\n",
        "def chat_with_agent(user_input):\n",
        "    global conversation_history\n",
        "    if 'translate' in user_input.lower():\n",
        "        return translate_to_english(user_input)\n",
        "    if \"bitcoin\" in user_input.lower() or \"price of\" in user_input.lower():\n",
        "        symbol = \"BTC\"  # Default to Bitcoin\n",
        "        if \"ethereum\" in user_input.lower():\n",
        "            symbol = \"ETH\"\n",
        "        return get_crypto_price(symbol)\n",
        "    conversation_history.append({\"role\": \"system\", \"content\": \"You are a helpful assistant that can access external functions. Your responsibility is to get the bitcoin price from the get_crypto_price tool and translate the text in whatever the language user ask for using the translate_to_english tool keeping the system message in English.\"},)\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": ques})\n",
        "    response = together.Completion.create(\n",
        "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "        prompt=\"\\n\".join([msg[\"content\"] for msg in conversation_history]),\n",
        "        max_tokens=1000\n",
        "    )\n",
        "    ai_response = response.choices[0].text\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "    return ai_response\n",
        "\n",
        "ques = \"translate 'आप कैसे हैं' in tamil\"\n",
        "print(chat_with_agent(ques))"
      ],
      "metadata": {
        "id": "6xzT8DjbyUB4",
        "outputId": "3a62ac85-b1cb-4ccc-83b5-2d0313d32d2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6xzT8DjbyUB4",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Translated from hindi): Translate 'How are you' in Tamil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import together\n",
        "\n",
        "# together.api_key = TOGETHER_API_KEY\n",
        "# conversation_history = []\n",
        "\n",
        "# def chat_with_agent(user_input):\n",
        "#     global conversation_history\n",
        "\n",
        "#     # If the user wants translation or asks for crypto prices, handle them separately\n",
        "#     if 'translate' in user_input.lower():\n",
        "#         return translate_to_english(user_input)\n",
        "\n",
        "#     if \"bitcoin\" in user_input.lower() or \"price of\" in user_input.lower():\n",
        "#         symbol = \"BTC\"  # Default to Bitcoin\n",
        "#         if \"ethereum\" in user_input.lower():\n",
        "#             symbol = \"ETH\"\n",
        "#         return get_crypto_price(symbol)\n",
        "\n",
        "#     # Adding system message to conversation history\n",
        "#     messages = [\n",
        "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant that can access external functions. Your responsibility is to get the bitcoin price from the get_crypto_price tool and translate the text in whatever the language user asks for using the translate_to_english tool, keeping the system message in English.\"},\n",
        "#     ]\n",
        "\n",
        "#     # Add user input to conversation history\n",
        "#     messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "#     # Send conversation history to the model for generating a response\n",
        "#     response = together.Completion.create(\n",
        "#         model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "#         # messages=messages,\n",
        "#         prompt=\"\\n\".join([msg[\"content\"] for msg in conversation_history]),\n",
        "#         max_tokens=1000\n",
        "#     )\n",
        "\n",
        "#     # AI's response\n",
        "#     ai_response = response.choices[0].text.strip()\n",
        "\n",
        "#     # Save AI response in history\n",
        "#     messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "\n",
        "#     return ai_response\n",
        "\n",
        "# # Example usage\n",
        "# ques = \"Who is the CEO of OpenAI?\"\n",
        "# print(chat_with_agent(ques))\n"
      ],
      "metadata": {
        "id": "Zfi6IFjI5Obq"
      },
      "id": "Zfi6IFjI5Obq",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyLYcvRCT3ZY",
        "outputId": "71c98ccd-cd1d-4a6e-cc21-3e14283ae7c9"
      },
      "id": "SyLYcvRCT3ZY",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Translated from latin): How are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_R9fvmLSmAV8"
      },
      "id": "_R9fvmLSmAV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AohbE6cvxKrV"
      },
      "id": "AohbE6cvxKrV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "\n",
        "# Set API Key\n",
        "together.api_key = \"your_together_api_key\"\n",
        "\n",
        "# Context storage\n",
        "conversation_history = []\n",
        "\n",
        "def chat_with_agent(user_input):\n",
        "    \"\"\"\n",
        "    AI Agent that:\n",
        "    - Translates non-English inputs to English\n",
        "    - Fetches cryptocurrency prices when needed\n",
        "    - Passes all responses to Llama 3.1 for structured output\n",
        "    \"\"\"\n",
        "    global conversation_history\n",
        "\n",
        "    # Step 1: Translate if needed\n",
        "    translated_input = translate_to_english(user_input)\n",
        "\n",
        "    # Step 2: Identify if it's a crypto query\n",
        "    crypto_response = \"\"\n",
        "    if \"bitcoin\" in translated_input.lower() or \"price of\" in translated_input.lower():\n",
        "        symbol = \"BTC\"\n",
        "        if \"ethereum\" in translated_input.lower():\n",
        "            symbol = \"ETH\"\n",
        "        crypto_response = get_crypto_price(symbol)\n",
        "\n",
        "    # Step 3: Prepare final prompt for Llama 3.1\n",
        "    final_prompt = f\"User input: {translated_input}\\n\\n\"\n",
        "    if crypto_response:\n",
        "        final_prompt += f\"Crypto Info: {crypto_response}\\n\\n\"\n",
        "    final_prompt += \"Provide a structured and conversational response.\"\n",
        "\n",
        "    # Step 4: Send to Llama 3.1\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": final_prompt})\n",
        "    response = together.Completion.create(\n",
        "        model=\"togethercomputer/llama-3-8b\",\n",
        "        prompt=\"\\n\".join([msg[\"content\"] for msg in conversation_history]),\n",
        "        max_tokens=100\n",
        "    )\n",
        "\n",
        "    ai_response = response[\"choices\"][0][\"text\"].strip()\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "\n",
        "    return ai_response"
      ],
      "metadata": {
        "id": "3w9nY3JPxKn1"
      },
      "id": "3w9nY3JPxKn1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}